"""
–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""
import asyncio
import json
import logging
import time
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from threading import Lock
from typing import Any, Callable, Dict, List, Optional

import psutil
import streamlit as st

logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    disk_io_read_bytes: int
    disk_io_write_bytes: int
    query_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    response_time_ms: float = 0.0
    active_connections: int = 0


@dataclass
class QueryStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    query_type: str
    db_type: str
    duration_ms: float
    cache_hit: bool
    timestamp: float
    records_count: int = 0


class PerformanceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.metrics_history = deque(maxlen=max_history)
        self.query_history = deque(maxlen=max_history)
        self.slow_queries = deque(maxlen=100)
        self.query_stats = defaultdict(lambda: {"count": 0, "total_time": 0})
        self.lock = Lock()
        self.start_time = time.time()
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        self.thresholds = {
            "cpu_percent": 80,
            "memory_percent": 85,
            "query_time_ms": 1000,
            "cache_hit_rate": 0.7
        }
    
    def collect_system_metrics(self) -> PerformanceMetrics:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        try:
            cpu = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory().percent
            disk = psutil.disk_io_counters()
            
            return PerformanceMetrics(
                timestamp=time.time(),
                cpu_percent=cpu,
                memory_percent=memory,
                disk_io_read_bytes=disk.read_bytes if disk else 0,
                disk_io_write_bytes=disk.write_bytes if disk else 0
            )
        except Exception as e:
            logger.error(f"Error collecting system metrics: {e}")
            return PerformanceMetrics(
                timestamp=time.time(),
                cpu_percent=0,
                memory_percent=0,
                disk_io_read_bytes=0,
                disk_io_write_bytes=0
            )
    
    def log_query(
        self,
        db_type: str,
        query_type: str,
        duration: float,
        records_count: int = 0,
        cache_hit: bool = False
    ):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—Ä–æ—Å–µ"""
        with self.lock:
            duration_ms = duration * 1000
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–ø—Ä–æ—Å–∞
            stats = QueryStats(
                query_type=query_type,
                db_type=db_type,
                duration_ms=duration_ms,
                cache_hit=cache_hit,
                timestamp=time.time(),
                records_count=records_count
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.query_history.append(stats)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            key = f"{db_type}:{query_type}"
            self.query_stats[key]["count"] += 1
            self.query_stats[key]["total_time"] += duration_ms
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            if duration_ms > self.thresholds["query_time_ms"]:
                self.slow_queries.append(stats)
                logger.warning(f"Slow query detected: {db_type}:{query_type} took {duration_ms:.2f}ms")
    
    def get_current_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏"""
        with self.lock:
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sys_metrics = self.collect_system_metrics()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
            cache_total = sum(1 for q in self.query_history if q.timestamp > time.time() - 60)
            cache_hits = sum(1 for q in self.query_history if q.cache_hit and q.timestamp > time.time() - 60)
            cache_hit_rate = (cache_hits / cache_total * 100) if cache_total > 0 else 0
            
            # –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
            recent_queries = [q for q in self.query_history if q.timestamp > time.time() - 60]
            avg_response_time = (
                sum(q.duration_ms for q in recent_queries) / len(recent_queries)
                if recent_queries else 0
            )
            
            return {
                "system": {
                    "cpu_percent": sys_metrics.cpu_percent,
                    "memory_percent": sys_metrics.memory_percent,
                    "disk_read_mb": sys_metrics.disk_io_read_bytes / (1024 * 1024),
                    "disk_write_mb": sys_metrics.disk_io_write_bytes / (1024 * 1024)
                },
                "queries": {
                    "total_last_minute": cache_total,
                    "cache_hit_rate": f"{cache_hit_rate:.1f}%",
                    "avg_response_time_ms": f"{avg_response_time:.2f}",
                    "slow_queries_count": len(self.slow_queries)
                },
                "uptime_hours": (time.time() - self.start_time) / 3600
            }
    
    def get_query_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤"""
        with self.lock:
            stats = {}
            
            for key, data in self.query_stats.items():
                avg_time = data["total_time"] / data["count"] if data["count"] > 0 else 0
                stats[key] = {
                    "count": data["count"],
                    "avg_time_ms": f"{avg_time:.2f}",
                    "total_time_ms": f"{data['total_time']:.2f}"
                }
            
            return stats
    
    def get_optimization_suggestions(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        suggestions = []
        metrics = self.get_current_metrics()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ CPU
        if metrics["system"]["cpu_percent"] > self.thresholds["cpu_percent"]:
            suggestions.append(f"‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CPU ({metrics['system']['cpu_percent']}%). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—è–∂–µ–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏.")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
        if metrics["system"]["memory_percent"] > self.thresholds["memory_percent"]:
            suggestions.append(f"‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ ({metrics['system']['memory_percent']}%). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏.")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_hit_rate = float(metrics["queries"]["cache_hit_rate"].rstrip('%'))
        if cache_hit_rate < self.thresholds["cache_hit_rate"] * 100:
            suggestions.append(f"üí° –ù–∏–∑–∫–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à ({cache_hit_rate}%). –£–≤–µ–ª–∏—á—å—Ç–µ —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞ –∏–ª–∏ TTL.")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if metrics["queries"]["slow_queries_count"] > 10:
            suggestions.append(f"üêå –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {metrics['queries']['slow_queries_count']} –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã.")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if self.slow_queries:
            slow_by_type = defaultdict(list)
            for q in self.slow_queries:
                slow_by_type[f"{q.db_type}:{q.query_type}"].append(q.duration_ms)
            
            for query_type, times in slow_by_type.items():
                avg_time = sum(times) / len(times)
                if avg_time > 2000:
                    suggestions.append(f"üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å {query_type}: —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è {avg_time:.0f}ms")
        
        if not suggestions:
            suggestions.append("‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ")
        
        return suggestions
    
    def export_metrics(self, filepath: str = "performance_report.json"):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–∞–π–ª"""
        with self.lock:
            report = {
                "timestamp": datetime.now().isoformat(),
                "current_metrics": self.get_current_metrics(),
                "query_statistics": self.get_query_statistics(),
                "slow_queries": [
                    {
                        "db_type": q.db_type,
                        "query_type": q.query_type,
                        "duration_ms": q.duration_ms,
                        "timestamp": datetime.fromtimestamp(q.timestamp).isoformat()
                    }
                    for q in list(self.slow_queries)[-20:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                ],
                "suggestions": self.get_optimization_suggestions()
            }
            
            Path(filepath).write_text(json.dumps(report, indent=2, ensure_ascii=False))
            logger.info(f"Performance report exported to {filepath}")
            
            return report


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–Ω–∏—Ç–æ—Ä–∞
performance_monitor = PerformanceMonitor()