"""
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
"""
import os
from pathlib import Path
from typing import Dict, Any

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data"


# -------------------------
# –ü—É—Ç–∏ –∫ –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö
# -------------------------
DATABASE_PATHS = {
    "metabolites": os.getenv("METABOLITES_DB_PATH", str(DATA_DIR / "metabolites.db")),
    "enzymes": os.getenv("ENZYMES_DB_PATH", str(DATA_DIR / "enzymes.db")),
    "proteins": os.getenv("PROTEINS_DB_PATH", str(DATA_DIR / "proteins.db")),
    "carbohydrates": os.getenv("CARBOHYDRATES_DB_PATH", str(DATA_DIR / "carbohydrates.db")),
    "lipids": os.getenv("LIPIDS_DB_PATH", str(DATA_DIR / "lipids.db")),
}

# -------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞
# -------------------------
SEARCH_CONFIG = {
    "default_page_size": 50,
    "max_page_size": 200,
    "min_page_size": 25,
    "default_tolerance_ppm": 1000,
    "max_tolerance_ppm": 10000,
    "min_tolerance_ppm": 250,
}

# -------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ UI
# -------------------------
UI_CONFIG = {
    "page_title": "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π",
    "page_icon": "üß¨",
    "layout": "centered",
    "cards_per_row": 3,
    "description_max_words": 6,
    "default_page_size": 50,  # –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
}

# -------------------------
# –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏
# -------------------------
EXTERNAL_LINKS = {
    "hmdb_base": "https://hmdb.ca/metabolites/",
    "kegg_base": "https://www.kegg.jp/entry/",
    "chebi_base": "https://www.ebi.ac.uk/chebi/searchId.do?chebiId=",
    "pubchem_base": "https://pubchem.ncbi.nlm.nih.gov/compound/",
    "uniprot_base": "https://www.uniprot.org/uniprot/",
    "pdb_base": "https://www.rcsb.org/structure/",
    "ncbi_gene_base": "https://www.ncbi.nlm.nih.gov/gene/?term=",
    "expasy_base": "https://enzyme.expasy.org/EC/",
}

# -------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# -------------------------
LOGGING_CONFIG = {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
}

# -------------------------
# –¢–∏–ø—ã –æ—Ä–≥–∞–Ω–∏–∑–º–æ–≤
# -------------------------
ORGANISM_TYPES = [
    "–í—Å–µ",
    "plant",
    "animal",
    "microorganism",
    "universal"
]

# -------------------------
# –ü—Ä–µ—Å–µ—Ç—ã –ø–æ–∏—Å–∫–∞
# -------------------------
SEARCH_PRESETS = {
    "glucose": "–ì–ª—é–∫–æ–∑–∞",
    "dehydrogenase": "Dehydrogenase",
    "formaldehyde": "Formaldehyde",
    "atp": "ATP",
}

# -------------------------
# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# -------------------------
def get_database_paths() -> Dict[str, str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç–∏ –∫ –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è"""
    missing_dbs = []
    existing_dbs = []
    
    print(f"Checking databases in: {DATA_DIR}")
    
    for db_type, path in DATABASE_PATHS.items():
        if os.path.exists(path):
            existing_dbs.append(f"{db_type}: {path}")
        else:
            missing_dbs.append(f"{db_type}: {path}")

    if existing_dbs:
        print(f"Found databases: {len(existing_dbs)}")
        for db in existing_dbs:
            print(f"  ‚úì {db}")
    
    if missing_dbs:
        print(f"Missing databases: {len(missing_dbs)}")
        for db in missing_dbs:
            print(f"  ‚úó {db}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏
        alt_data_dir = DATA_DIR / "data"
        if alt_data_dir.exists():
            print(f"Found alternative data directory: {alt_data_dir}")
            for db_type in missing_dbs:
                db_name = db_type.split(':')[0] + ".db"
                alt_path = alt_data_dir / db_name
                if alt_path.exists():
                    print(f"  Alternative found: {alt_path}")

        raise FileNotFoundError(
            f"–°–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–π–ª—ã –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {', '.join(db.split(': ')[1] for db in missing_dbs)}"
        )

    return DATABASE_PATHS

def validate_search_params(query: str = None, mass: float = None, tolerance_ppm: int = None) -> Dict[str, Any]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞"""
    errors = []

    if query and len(query.strip()) < 2:
        errors.append("–ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 2 —Å–∏–º–≤–æ–ª–∞")

    if mass and (not isinstance(mass, (int, float)) or mass <= 0 or mass > 1000000):
        errors.append("–ú–∞—Å—Å–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º –¥–æ 1,000,000")

    if tolerance_ppm:
        if tolerance_ppm < SEARCH_CONFIG["min_tolerance_ppm"]:
            errors.append(f"–î–æ–ø—É—Å–∫ PPM –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –º–µ–Ω–µ–µ {SEARCH_CONFIG['min_tolerance_ppm']}")
        if tolerance_ppm > SEARCH_CONFIG["max_tolerance_ppm"]:
            errors.append(f"–î–æ–ø—É—Å–∫ PPM –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ –±–æ–ª–µ–µ {SEARCH_CONFIG['max_tolerance_ppm']}")

    return {"valid": len(errors) == 0, "errors": errors}
