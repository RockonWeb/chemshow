"""
–°–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
AI-powered –ø–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from typing import Dict, Any, List, Optional, Tuple
import logging
import sqlite3
import re
import math
import os
from collections import defaultdict

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
try:
    # Try absolute import first
    from components.utils import get_display_name, safe_get_value, format_mass
except ImportError:
    # Fallback to relative import
    try:
        from .utils import get_display_name, safe_get_value, format_mass
    except ImportError:
        from utils import get_display_name, safe_get_value, format_mass

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å RDKit –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
try:
    from rdkit import Chem
    from rdkit.Chem import AllChem, DataStructs, Descriptors
    from rdkit.Chem.Fingerprints import FingerprintMols
    RDKIT_AVAILABLE = True
    logger.info("RDKit –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
except ImportError:
    RDKIT_AVAILABLE = False
    logger.warning("RDKit –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω - –±–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã")


class RecommendationsEngine:
    """–î–≤–∏–∂–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""

    def __init__(self):
        self.compound_cache = {}
        self.similarity_cache = {}

    def _clean_smiles_data(self, compound: Dict[str, Any]) -> Dict[str, Any]:
        """–û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ SMILES –æ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        cleaned_compound = compound.copy()
        
        # –û—á–∏—â–∞–µ–º SMILES –ø–æ–ª–µ
        if 'smiles' in cleaned_compound:
            smiles = cleaned_compound['smiles']
            if not self._is_valid_smiles(smiles):
                cleaned_compound['smiles'] = None
                logger.debug(f"–û—á–∏—â–µ–Ω –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π SMILES –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è {cleaned_compound.get('name', 'Unknown')}")
        
        return cleaned_compound

    def find_similar_compounds(self, target_compound: Dict[str, Any],
                              database_type: str, limit: int = 10,
                              compounds_list: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
        """
        try:
            if compounds_list is not None:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                compounds_data = compounds_list
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                # Try absolute import first
                try:
                    from config.settings import DATABASE_PATHS
                except ImportError:
                    # Fallback to relative import
                    from ..config.settings import DATABASE_PATHS

                if database_type not in DATABASE_PATHS:
                    return []

                db_path = DATABASE_PATHS[database_type]
                if not os.path.exists(db_path):
                    return []

                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()

                similar_compounds = []

                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                cursor.execute(f"SELECT * FROM {database_type}")
                all_compounds = cursor.fetchall()

                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
                cursor.execute(f"PRAGMA table_info({database_type})")
                columns = [row[1] for row in cursor.fetchall()]

                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä–∏ –∏ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                compounds_data = []
                for row in all_compounds:
                    compound_dict = dict(zip(columns, row))
                    # –û—á–∏—â–∞–µ–º SMILES –¥–∞–Ω–Ω—ã–µ
                    cleaned_compound = self._clean_smiles_data(compound_dict)
                    compounds_data.append(cleaned_compound)

                conn.close()

            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            similarities = []
            for compound in compounds_data:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ü–µ–ª–µ–≤–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                if compound.get('id') == target_compound.get('id'):
                    continue

                similarity_score = self._calculate_similarity(target_compound, compound, database_type)
                similarities.append((compound, similarity_score))

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø
            similarities.sort(key=lambda x: x[1], reverse=True)
            similar_compounds = [comp for comp, score in similarities[:limit] if score > 0]

            return similar_compounds

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")
            return []

    def _calculate_similarity(self, compound1: Dict[str, Any],
                            compound2: Dict[str, Any], database_type: str) -> float:
        """
        –†–∞—Å—á–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏
        """
        similarity = 0.0

        # 1. –°—Ö–æ–∂–µ—Å—Ç—å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫)
        name_sim = self._text_similarity(
            compound1.get('name', ''),
            compound2.get('name', '')
        )
        similarity += name_sim * 0.3

        # 2. –°—Ö–æ–∂–µ—Å—Ç—å –ø–æ —Ñ–æ—Ä–º—É–ª–µ (–¥–ª—è –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π)
        if database_type in ['metabolites', 'carbohydrates', 'lipids']:
            formula_sim = self._formula_similarity(
                compound1.get('formula', ''),
                compound2.get('formula', '')
            )
            similarity += formula_sim * 0.4

        # 3. –°—Ö–æ–∂–µ—Å—Ç—å –ø–æ –º–∞—Å—Å–µ
        mass_sim = self._mass_similarity(
            compound1.get('exact_mass'),
            compound2.get('exact_mass')
        )
        similarity += mass_sim * 0.2

        # 4. –°—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω RDKit)
        if RDKIT_AVAILABLE and compound1.get('smiles') and compound2.get('smiles'):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å SMILES –ø–µ—Ä–µ–¥ —Ä–∞—Å—á–µ—Ç–æ–º
            if self._is_valid_smiles(compound1.get('smiles')) and self._is_valid_smiles(compound2.get('smiles')):
                struct_sim = self._structural_similarity(
                    compound1.get('smiles'),
                    compound2.get('smiles')
                )
                similarity += struct_sim * 0.5
            else:
                # –ï—Å–ª–∏ SMILES –Ω–µ–≤–∞–ª–∏–¥–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ SMILES")

        # 5. –°—Ö–æ–∂–µ—Å—Ç—å –ø–æ —Å–≤–æ–π—Å—Ç–≤–∞–º
        if database_type == 'enzymes':
            prop_sim = self._enzyme_similarity(compound1, compound2)
            similarity += prop_sim * 0.3
        elif database_type == 'proteins':
            prop_sim = self._protein_similarity(compound1, compound2)
            similarity += prop_sim * 0.3

        return min(similarity, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 1.0

    def _text_similarity(self, text1: str, text2: str) -> float:
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        if not text1 or not text2:
            return 0.0

        # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö —Å–ª–æ–≤
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union) if union else 0.0

    def _formula_similarity(self, formula1: str, formula2: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª"""
        if not formula1 or not formula2:
            return 0.0

        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        elements1 = self._parse_formula(formula1)
        elements2 = self._parse_formula(formula2)

        if not elements1 or not elements2:
            return 0.0

        # Jaccard similarity –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        set1 = set(elements1.keys())
        set2 = set(elements2.keys())

        intersection = set1.intersection(set2)
        union = set1.union(set2)

        return len(intersection) / len(union) if union else 0.0

    def _parse_formula(self, formula: str) -> Dict[str, int]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ö–∏–º–∏—á–µ—Å–∫–æ–π —Ñ–æ—Ä–º—É–ª—ã"""
        elements = {}
        # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        pattern = r'([A-Z][a-z]?)(\d*)'
        matches = re.findall(pattern, formula)

        for element, count in matches:
            count = int(count) if count else 1
            elements[element] = elements.get(element, 0) + count

        return elements

    def _mass_similarity(self, mass1: float, mass2: float) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –ø–æ –º–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –º–∞—Å—Å–µ"""
        if mass1 is None or mass2 is None:
            return 0.0

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–∞—É—Å—Å–æ–≤–æ —Å—Ö–æ–¥—Å—Ç–≤–æ
        diff = abs(mass1 - mass2)
        sigma = max(mass1, mass2) * 0.1  # 10% –æ—Ç –±–æ–ª—å—à–µ–π –º–∞—Å—Å—ã

        return math.exp(-(diff ** 2) / (2 * sigma ** 2))

    def _structural_similarity(self, smiles1: str, smiles2: str) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RDKit"""
        if not RDKIT_AVAILABLE:
            return 0.0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å SMILES
        if not self._is_valid_smiles(smiles1) or not self._is_valid_smiles(smiles2):
            return 0.0

        try:
            mol1 = Chem.MolFromSmiles(smiles1)
            mol2 = Chem.MolFromSmiles(smiles2)

            if mol1 is None or mol2 is None:
                return 0.0

            # Morgan fingerprints
            fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=1024)
            fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=1024)

            # Tanimoto similarity
            return DataStructs.TanimotoSimilarity(fp1, fp2)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0

    def _is_valid_smiles(self, smiles: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤–∞–ª–∏–¥–Ω—ã–º SMILES"""
        if not smiles or not isinstance(smiles, str):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        invalid_values = ['0', 'None', 'null', '', 'nan', 'NaN']
        if smiles in invalid_values:
            logger.debug(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π SMILES: '{smiles}'")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ SMILES —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª
        if len(smiles.strip()) < 2:
            logger.debug(f"SMILES —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: '{smiles}'")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ SMILES —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        chemical_chars = set('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789()[]{}@+-=#$%:;,.')
        if not any(char in chemical_chars for char in smiles):
            logger.debug(f"SMILES –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤: '{smiles}'")
            return False
        
        return True

    def _enzyme_similarity(self, enzyme1: Dict[str, Any], enzyme2: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ —Ñ–µ—Ä–º–µ–Ω—Ç–æ–≤"""
        similarity = 0.0

        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ EC –Ω–æ–º–µ—Ä—É
        ec1 = enzyme1.get('ec_number', '')
        ec2 = enzyme2.get('ec_number', '')

        if ec1 and ec2:
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö —Ü–∏—Ñ—Ä EC –Ω–æ–º–µ—Ä–∞
            ec_parts1 = ec1.split('.')
            ec_parts2 = ec2.split('.')

            matches = 0
            for i in range(min(len(ec_parts1), len(ec_parts2))):
                if ec_parts1[i] == ec_parts2[i]:
                    matches += 1
                else:
                    break

            similarity += (matches / 4.0) * 0.5  # EC –Ω–æ–º–µ—Ä –∏–º–µ–µ—Ç 4 —É—Ä–æ–≤–Ω—è

        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤—É
        family1 = enzyme1.get('family', '')
        family2 = enzyme2.get('family', '')

        if family1 and family2:
            if family1.lower() == family2.lower():
                similarity += 0.3

        return similarity

    def _protein_similarity(self, protein1: Dict[str, Any], protein2: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–∞ –±–µ–ª–∫–æ–≤"""
        similarity = 0.0

        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ —Ñ—É–Ω–∫—Ü–∏–∏
        func1 = protein1.get('function', '')
        func2 = protein2.get('function', '')

        if func1 and func2:
            func_sim = self._text_similarity(func1, func2)
            similarity += func_sim * 0.4

        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ —Å–µ–º–µ–π—Å—Ç–≤—É
        family1 = protein1.get('family', '')
        family2 = protein2.get('family', '')

        if family1 and family2:
            if family1.lower() == family2.lower():
                similarity += 0.3

        # –°—Ö–æ–¥—Å—Ç–≤–æ –ø–æ –æ—Ä–≥–∞–Ω–∏–∑–º—É
        org1 = protein1.get('organism', '')
        org2 = protein2.get('organism', '')

        if org1 and org2:
            if org1.lower() == org2.lower():
                similarity += 0.3

        return similarity

    def _apply_filters(self, compounds: List[Dict[str, Any]], mass_range: tuple,
                      smiles_only: bool, keyword_filter: str,
                      formula_elements: List[str]) -> List[Dict[str, Any]]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∫ —Å–ø–∏—Å–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        filtered_compounds = []

        for compound in compounds:
            # –§–∏–ª—å—Ç—Ä –ø–æ –º–∞—Å—Å–µ
            mass = compound.get('exact_mass')
            if mass is not None and (mass < mass_range[0] or mass > mass_range[1]):
                continue

            # –§–∏–ª—å—Ç—Ä –ø–æ SMILES
            if smiles_only and not self._is_valid_smiles(compound.get('smiles', '')):
                continue

            # –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            if keyword_filter:
                keywords = [kw.strip().lower() for kw in keyword_filter.split(',')]
                name = compound.get('name', '').lower()
                if not any(keyword in name for keyword in keywords):
                    continue

            # –§–∏–ª—å—Ç—Ä –ø–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤ —Ñ–æ—Ä–º—É–ª–µ
            if formula_elements:
                formula = compound.get('formula', '')
                if formula:
                    elements_in_formula = set(self._parse_formula(formula).keys())
                    if not all(elem in elements_in_formula for elem in formula_elements):
                        continue

            filtered_compounds.append(compound)

        return filtered_compounds

    def _create_clustering_features(self, compounds: List[Dict[str, Any]],
                                   database_type: str) -> Tuple[List[List[float]], List[str]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"""
        features = []
        feature_names = []

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        base_features = ['mass', 'name_length', 'formula_length']
        feature_names.extend(base_features)

        for compound in compounds:
            feature_vector = []

            # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            mass = compound.get('exact_mass', 0)
            feature_vector.append(float(mass) if mass else 0.0)

            name_len = len(compound.get('name', ''))
            feature_vector.append(float(name_len))

            formula_len = len(compound.get('formula', ''))
            feature_vector.append(float(formula_len))

            # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Ç–∏–ø–∞–º
            if database_type in ['metabolites', 'carbohydrates', 'lipids']:
                # –•–∏–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                elements = self._parse_formula(compound.get('formula', ''))
                feature_vector.append(float(len(elements)))  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                feature_vector.append(float(sum(elements.values())))  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç–æ–º–æ–≤

                # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                class_len = len(compound.get('class_name', ''))
                feature_vector.append(float(class_len))

                feature_names.extend(['elements_count', 'atoms_total', 'class_length'])

                # –ú–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å SMILES)
                if RDKIT_AVAILABLE and compound.get('smiles'):
                    try:
                        mol = Chem.MolFromSmiles(compound.get('smiles'))
                        if mol:
                            feature_vector.append(float(Chem.rdMolDescriptors.CalcNumHBD(mol)))  # H-bond donors
                            feature_vector.append(float(Chem.rdMolDescriptors.CalcNumHBA(mol)))  # H-bond acceptors
                            feature_vector.append(float(Descriptors.MolLogP(mol)))  # LogP
                            feature_vector.append(float(Descriptors.MolWt(mol)))   # Molecular weight
                            feature_names.extend(['hbd', 'hba', 'logp', 'molwt'])
                        else:
                            # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–∏ –µ—Å–ª–∏ SMILES –Ω–µ–≤–∞–ª–∏–¥–µ–Ω
                            feature_vector.extend([0.0, 0.0, 0.0, 0.0])
                            feature_names.extend(['hbd', 'hba', 'logp', 'molwt'])
                    except:
                        feature_vector.extend([0.0, 0.0, 0.0, 0.0])
                        feature_names.extend(['hbd', 'hba', 'logp', 'molwt'])
                else:
                    feature_vector.extend([0.0, 0.0, 0.0, 0.0])
                    feature_names.extend(['hbd', 'hba', 'logp', 'molwt'])

            elif database_type == 'enzymes':
                # EC –Ω–æ–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–∏
                ec_number = compound.get('ec_number', '0.0.0.0')
                ec_parts = ec_number.split('.')
                for i in range(4):
                    if i < len(ec_parts):
                        try:
                            feature_vector.append(float(ec_parts[i]))
                        except:
                            feature_vector.append(0.0)
                    else:
                        feature_vector.append(0.0)

                feature_names.extend(['ec1', 'ec2', 'ec3', 'ec4'])

                # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                family_len = len(compound.get('family', ''))
                feature_vector.append(float(family_len))
                feature_names.append('family_length')

            elif database_type == 'proteins':
                # –ë–µ–ª–∫–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                seq_len = compound.get('sequence_length', 0)
                feature_vector.append(float(seq_len) if seq_len else 0.0)

                func_len = len(compound.get('function', ''))
                feature_vector.append(float(func_len))

                family_len = len(compound.get('family', ''))
                feature_vector.append(float(family_len))

                feature_names.extend(['seq_length', 'func_length', 'family_length'])

            features.append(feature_vector)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_names = list(dict.fromkeys(feature_names))

        return features, feature_names

    def save_recommendation_session(self, session_data: Dict[str, Any], session_name: str) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        try:
            import json
            import os
            from datetime import datetime

            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–µ—Å—Å–∏–π –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            sessions_dir = os.path.join(os.path.dirname(__file__), '..', 'sessions')
            os.makedirs(sessions_dir, exist_ok=True)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏
            session_data['metadata'] = {
                'name': session_name,
                'timestamp': datetime.now().isoformat(),
                'version': '1.0'
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ—Å—Å–∏—é
            session_file = os.path.join(sessions_dir, f"{session_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")

            with open(session_file, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, ensure_ascii=False, indent=2, default=str)

            logger.info(f"–°–µ—Å—Å–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {session_file}")
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            return False

    def load_recommendation_sessions(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π"""
        try:
            import os
            import json
            from datetime import datetime

            sessions_dir = os.path.join(os.path.dirname(__file__), '..', 'sessions')
            if not os.path.exists(sessions_dir):
                return []

            sessions = []
            for filename in os.listdir(sessions_dir):
                if filename.endswith('.json'):
                    try:
                        filepath = os.path.join(sessions_dir, filename)
                        with open(filepath, 'r', encoding='utf-8') as f:
                            session_data = json.load(f)

                        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
                        session_data['file_info'] = {
                            'filename': filename,
                            'filepath': filepath,
                            'file_size': os.path.getsize(filepath)
                        }

                        sessions.append(session_data)
                    except Exception as e:
                        logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–∏ {filename}: {e}")

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
            sessions.sort(key=lambda x: x.get('metadata', {}).get('timestamp', ''), reverse=True)
            return sessions

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Å—Å–∏–π: {e}")
            return []

    def delete_recommendation_session(self, session_filename: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        try:
            import os
            sessions_dir = os.path.join(os.path.dirname(__file__), '..', 'sessions')
            filepath = os.path.join(sessions_dir, session_filename)

            if os.path.exists(filepath):
                os.remove(filepath)
                logger.info(f"–°–µ—Å—Å–∏—è —É–¥–∞–ª–µ–Ω–∞: {session_filename}")
                return True
            else:
                logger.warning(f"–§–∞–π–ª —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {session_filename}")
                return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            return False

    def cluster_compounds(self, compounds: List[Dict[str, Any]],
                         database_type: str, n_clusters: int = 5,
                         algorithm: str = "kmeans") -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤"""
        if not compounds or len(compounds) < 2:
            return {"error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏"}

        if len(compounds) < n_clusters and algorithm == "kmeans":
            n_clusters = max(2, len(compounds) // 2)  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞

        try:
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            features, feature_names = self._create_clustering_features(compounds, database_type)

            if not features:
                return {"error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"}

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            import numpy as np
            features_array = np.array(features)
            from sklearn.preprocessing import StandardScaler
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features_array)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º
            if algorithm == "kmeans":
                from sklearn.cluster import KMeans
                if len(compounds) < n_clusters:
                    n_clusters = max(2, len(compounds) // 2)
                cluster_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                clusters = cluster_model.fit_predict(features_scaled)
                centroids = cluster_model.cluster_centers_

            elif algorithm == "dbscan":
                from sklearn.cluster import DBSCAN
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä eps –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
                from sklearn.neighbors import NearestNeighbors
                neighbors = NearestNeighbors(n_neighbors=5)
                neighbors_fit = neighbors.fit(features_scaled)
                distances, indices = neighbors_fit.kneighbors(features_scaled)
                distances = np.sort(distances, axis=0)
                distances = distances[:, 1]
                eps = np.percentile(distances, 90)  # 90-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å
                cluster_model = DBSCAN(eps=eps, min_samples=max(2, len(compounds) // 20))
                clusters = cluster_model.fit_predict(features_scaled)
                centroids = None
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (DBSCAN –º–æ–∂–µ—Ç –¥–∞—Ç—å -1 –¥–ª—è —à—É–º–æ–≤—ã—Ö —Ç–æ—á–µ–∫)
                n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)

            elif algorithm == "agglomerative":
                from sklearn.cluster import AgglomerativeClustering
                cluster_model = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')
                clusters = cluster_model.fit_predict(features_scaled)
                centroids = None

            else:
                return {"error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {algorithm}"}

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
            from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score

            quality_metrics = {}
            try:
                if n_clusters > 1 and len(set(clusters)) > 1:
                    quality_metrics['silhouette'] = silhouette_score(features_scaled, clusters)
                    quality_metrics['calinski_harabasz'] = calinski_harabasz_score(features_scaled, clusters)
                    quality_metrics['davies_bouldin'] = davies_bouldin_score(features_scaled, clusters)
                else:
                    quality_metrics = {"warning": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"}
            except:
                quality_metrics = {"warning": "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"}

            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            cluster_results = {}
            for i, cluster_id in enumerate(clusters):
                if cluster_id not in cluster_results:
                    cluster_results[cluster_id] = []
                cluster_results[cluster_id].append(compounds[i])

            return {
                "clusters": cluster_results,
                "n_clusters": n_clusters,
                "total_compounds": len(compounds),
                "algorithm": algorithm,
                "quality_metrics": quality_metrics,
                "feature_names": feature_names,
                "centroids": centroids.tolist() if centroids is not None else None
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return {"error": str(e)}

    def get_recommendation_explanation(self, target_compound: Dict[str, Any],
                                     similar_compound: Dict[str, Any],
                                     similarity_score: float) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        explanations = []

        # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        name1 = target_compound.get('name', '').lower()
        name2 = similar_compound.get('name', '').lower()

        if name1 and name2:
            common_words = set(name1.split()) & set(name2.split())
            if common_words:
                explanations.append(f"–û–±—â–∏–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö: {', '.join(common_words)}")

        # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ñ–æ—Ä–º—É–ª–µ
        formula1 = target_compound.get('formula', '')
        formula2 = similar_compound.get('formula', '')

        if formula1 and formula2:
            elements1 = set(self._parse_formula(formula1).keys())
            elements2 = set(self._parse_formula(formula2).keys())
            common_elements = elements1 & elements2

            if common_elements:
                explanations.append(f"–û–±—â–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã: {', '.join(common_elements)}")

        # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ –º–∞—Å—Å–µ
        mass1 = target_compound.get('exact_mass')
        mass2 = similar_compound.get('exact_mass')

        if mass1 and mass2:
            mass_diff = abs(mass1 - mass2)
            if mass_diff < 10:
                explanations.append(f"–û—á–µ–Ω—å –±–ª–∏–∑–∫–∏–µ –º–∞—Å—Å—ã: {mass1:.1f} vs {mass2:.1f} Da")
            elif mass_diff < 100:
                explanations.append(f"–ë–ª–∏–∑–∫–∏–µ –º–∞—Å—Å—ã: {mass1:.1f} vs {mass2:.1f} Da")
        # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        if RDKIT_AVAILABLE and similarity_score > 0.7:
            explanations.append("–í—ã—Å–æ–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –º–æ–ª–µ–∫—É–ª")

        if not explanations:
            explanations.append(f"–û–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏: {similarity_score:.2f}")

        return "; ".join(explanations)


def render_recommendations_interface():
    """–û—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    st.header("üéØ –°–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")

    engine = RecommendationsEngine()

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
    with st.expander("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π"):
        saved_sessions = engine.load_recommendation_sessions()

        if saved_sessions:
            session_options = [f"{s.get('metadata', {}).get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} - {s.get('metadata', {}).get('timestamp', '')[:19]}" for s in saved_sessions]
            selected_session_idx = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ—Å—Å–∏—é –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏:",
                options=range(len(saved_sessions)),
                format_func=lambda x: session_options[x] if x < len(session_options) else "‚Äî"
            )

            col1, col2 = st.columns(2)
            with col1:
                if st.button("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ—Å—Å–∏—é", use_container_width=True):
                    session_data = saved_sessions[selected_session_idx]
                    st.session_state.recommendation_results = session_data.get('recommendations', [])
                    st.session_state.target_compound = session_data.get('target_compound', {})
                    st.session_state.filters_applied = session_data.get('filters', {})
                    st.success("‚úÖ –°–µ—Å—Å–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∏–∂–µ.")

            with col2:
                if st.button("üóëÔ∏è –£–¥–∞–ª–∏—Ç—å —Å–µ—Å—Å–∏—é", use_container_width=True):
                    filename = saved_sessions[selected_session_idx].get('file_info', {}).get('filename')
                    if filename and engine.delete_recommendation_session(filename):
                        st.success("‚úÖ –°–µ—Å—Å–∏—è —É–¥–∞–ª–µ–Ω–∞!")
                        st.rerun()  # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
                    else:
                        st.error("‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏")
        else:
            st.info("üí° –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø–æ–∏—Å–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")

    st.divider()

    # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞
    database_options = {
        "metabolites": "üß¨ –ú–µ—Ç–∞–±–æ–ª–∏—Ç—ã",
        "enzymes": "üß™ –§–µ—Ä–º–µ–Ω—Ç—ã",
        "proteins": "üî¨ –ë–µ–ª–∫–∏",
        "carbohydrates": "üåæ –£–≥–ª–µ–≤–æ–¥—ã",
        "lipids": "ü´ß –õ–∏–ø–∏–¥—ã"
    }

    selected_db = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
        options=list(database_options.keys()),
        format_func=lambda x: database_options[x]
    )

    if selected_db:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –±–∞–∑—ã
        try:
            # Try absolute import first
            from config.settings import DATABASE_PATHS
        except ImportError:
            # Fallback to relative import
            from ..config.settings import DATABASE_PATHS

            db_path = DATABASE_PATHS[selected_db]
            if os.path.exists(db_path):
                try:
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                    cursor.execute(f"PRAGMA table_info({selected_db})")
                    columns = [row[1] for row in cursor.fetchall()]

                    if not columns:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞: —Ç–∞–±–ª–∏—Ü–∞ {selected_db} –ø—É—Å—Ç–∞—è –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                        return

                    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (—É–≤–µ–ª–∏—á–µ–Ω –ª–∏–º–∏—Ç –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)
                    cursor.execute(f"SELECT * FROM {selected_db} LIMIT 1000")  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                    compounds = cursor.fetchall()

                    compounds_list = [dict(zip(columns, row)) for row in compounds]
                    conn.close()

                    if not compounds_list:
                        st.warning(f"‚ö†Ô∏è –í —Ç–∞–±–ª–∏—Ü–µ {selected_db} –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö")
                        return

                except sqlite3.Error as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    logger.error(f"Database error for {selected_db}: {e}")
                    return
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                    logger.error(f"Error loading data from {selected_db}: {e}")
                    return
            else:
                st.error(f"‚ùå –§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö {db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return

            if compounds_list:
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(compounds_list)} —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏–∑ –±–∞–∑—ã {database_options[selected_db]}")

                    # –û—á–∏—â–∞–µ–º SMILES –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                    cleaned_compounds = []
                    for compound in compounds_list:
                        cleaned_compound = engine._clean_smiles_data(compound)
                        cleaned_compounds.append(cleaned_compound)
                    
                    compounds_list = cleaned_compounds

                    # –í—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                    compound_names = [f"{c.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} (ID: {c.get('id', '‚Äî')})" for c in compounds_list]
                    selected_compound_idx = st.selectbox(
                        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–æ–≤:",
                        options=range(len(compounds_list)),
                        format_func=lambda x: compound_names[x]
                    )

                    target_compound = compounds_list[selected_compound_idx]

                    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
                    st.subheader("‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞")

                    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    col1, col2 = st.columns(2)
                    with col1:
                        limit = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:", 5, 50, 10)
                    with col2:
                        min_similarity = st.slider("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å (%):", 0, 100, 30) / 100.0

                    # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
                    with st.expander("üîç –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã"):
                        col3, col4 = st.columns(2)

                        with col3:
                            # –§–∏–ª—å—Ç—Ä –ø–æ –º–∞—Å—Å–µ
                            mass_range = st.slider(
                                "–î–∏–∞–ø–∞–∑–æ–Ω –º–∞—Å—Å—ã (Da):",
                                0.0, 2000.0, (0.0, 2000.0),
                                help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø–æ–∏—Å–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –º–∞—Å—Å"
                            )

                        with col4:
                            # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–ª–∏—á–∏—é SMILES
                            smiles_only = st.checkbox(
                                "–¢–æ–ª—å–∫–æ —Å SMILES",
                                help="–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ SMILES –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
                            )

                        # –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                        keyword_filter = st.text_input(
                            "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏:",
                            placeholder="–Ω–∞–ø—Ä–∏–º–µ—Ä: glucose, dehydrogenase",
                            help="–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"
                        )

                        # –§–∏–ª—å—Ç—Ä –ø–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤ —Ñ–æ—Ä–º—É–ª–µ
                        formula_elements = st.multiselect(
                            "–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º—É–ª–µ:",
                            options=["C", "H", "O", "N", "P", "S", "Cl", "Br", "I", "F"],
                            help="–°–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ö–∏–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã"
                        )

                    # –ü–æ–∏—Å–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                    if st.button("üîç –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è", type="primary", width='stretch'):
                        with st.spinner("–ò—â—É –ø–æ—Ö–æ–∂–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è..."):
                            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –∫ —Å–ø–∏—Å–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º
                            filtered_compounds_list = engine._apply_filters(
                                compounds_list, mass_range, smiles_only, keyword_filter, formula_elements
                            )

                            if len(filtered_compounds_list) < 2:
                                st.warning("‚ö†Ô∏è –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
                                return

                            similar_compounds = engine.find_similar_compounds(
                                target_compound, selected_db, limit, filtered_compounds_list
                            )

                            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏
                            final_filtered_compounds = []
                            for comp in similar_compounds:
                                similarity = engine._calculate_similarity(target_compound, comp, selected_db)
                                if similarity >= min_similarity:
                                    final_filtered_compounds.append((comp, similarity))

                            st.session_state.recommendation_results = final_filtered_compounds
                            st.session_state.target_compound = target_compound
                            st.session_state.filters_applied = {
                                'mass_range': mass_range,
                                'smiles_only': smiles_only,
                                'keyword_filter': keyword_filter,
                                'formula_elements': formula_elements
                            }

                            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
                            st.divider()
                            st.subheader("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏")

                            session_name = st.text_input(
                                "–ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏:",
                                placeholder="–ú–æ—è —Å–µ—Å—Å–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π",
                                help="–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"
                            )

                            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–µ—Å—Å–∏—é", type="secondary", use_container_width=True):
                                if session_name.strip():
                                    session_data = {
                                        'recommendations': st.session_state.recommendation_results,
                                        'target_compound': st.session_state.target_compound,
                                        'filters': st.session_state.filters_applied,
                                        'database_type': selected_db,
                                        'timestamp': pd.Timestamp.now().isoformat()
                                    }

                                    if engine.save_recommendation_session(session_data, session_name.strip()):
                                        st.success(f"‚úÖ –°–µ—Å—Å–∏—è '{session_name}' —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
                                    else:
                                        st.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏")
                                else:
                                    st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏")

                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    if 'recommendation_results' in st.session_state and st.session_state.recommendation_results:
                        results = st.session_state.recommendation_results
                        target = st.session_state.target_compound

                        st.subheader(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è: {target.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")

                        # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        result_data = []
                        for comp, similarity in results:
                            result_data.append({
                                "–ù–∞–∑–≤–∞–Ω–∏–µ": comp.get('name', '‚Äî'),
                                "–°—Ö–æ–∂–µ—Å—Ç—å": f"{similarity:.1%}",
                                "–§–æ—Ä–º—É–ª–∞": comp.get('formula', '‚Äî'),
                                "–ú–∞—Å—Å–∞ (Da)": f"{comp.get('exact_mass', 0):.2f}" if comp.get('exact_mass') else "‚Äî",
                                "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ": engine.get_recommendation_explanation(target, comp, similarity)
                            })

                        if result_data:
                            df = pd.DataFrame(result_data)

                            st.dataframe(
                                df,
                                width='stretch',
                                hide_index=True,
                                column_config={
                                    "–ù–∞–∑–≤–∞–Ω–∏–µ": st.column_config.TextColumn(width="large"),
                                    "–°—Ö–æ–∂–µ—Å—Ç—å": st.column_config.TextColumn(width="small"),
                                    "–§–æ—Ä–º—É–ª–∞": st.column_config.TextColumn(width="medium"),
                                    "–ú–∞—Å—Å–∞ (Da)": st.column_config.NumberColumn(width="small", format="%.2f"),
                                    "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ": st.column_config.TextColumn(width="large")
                                }
                            )

                            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            st.subheader("üîß –î–µ–π—Å—Ç–≤–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏")
                            
                            for i, (comp, similarity) in enumerate(results):
                                with st.container():
                                    col1, col2 = st.columns([3, 1])
                                    
                                    with col1:
                                        st.markdown(f"**{comp.get('name', '‚Äî')}** (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.1%})")
                                    
                                    with col2:
                                        # –ö–Ω–æ–ø–∫–∞ –ø–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏
                                        if st.button(f"üìã –î–µ—Ç–∞–ª–∏", key=f"details_{i}_{comp.get('id', i)}", use_container_width=True):
                                            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥ –¥–µ—Ç–∞–ª–µ–π
                                            try:
                                                from ..main import open_dialog_safely
                                            except ImportError:
                                                try:
                                                    from main import open_dialog_safely
                                                except ImportError:
                                                    # Fallback —Ñ—É–Ω–∫—Ü–∏—è
                                                    def open_dialog_safely(dialog_type: str, entity: Dict[str, Any]):
                                                        st.session_state[f"show_{dialog_type}_details"] = True
                                                        st.session_state[f"selected_{dialog_type}"] = entity
                                                    
                                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                                            if selected_db == "metabolites":
                                                open_dialog_safely("metabolite", comp)
                                            elif selected_db == "enzymes":
                                                open_dialog_safely("enzyme", comp)
                                            elif selected_db == "proteins":
                                                open_dialog_safely("protein", comp)
                                            elif selected_db == "carbohydrates":
                                                open_dialog_safely("carbohydrate", comp)
                                            elif selected_db == "lipids":
                                                open_dialog_safely("lipid", comp)
                                        
                                        # –ö–Ω–æ–ø–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é
                                        if st.button(f"‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å", key=f"compare_{i}_{comp.get('id', i)}", use_container_width=True):
                                            try:
                                                from .comparison import add_to_comparison_button, comparison_comparator
                                                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é
                                                add_to_comparison_button(comp, selected_db, comparison_comparator)
                                                st.success(f"‚úÖ {comp.get('name', '–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ')} –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é")
                                            except Exception as e:
                                                st.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é: {e}")
                                    
                                    st.divider()

                            # –î–∏–∞–≥—Ä–∞–º–º–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
                            st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏")

                            similarities = [sim for _, sim in results]
                            names = [comp.get('name', '‚Äî')[:30] for comp, _ in results]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

                            if similarities:
                                fig = go.Figure(data=[
                                    go.Bar(
                                        x=names,
                                        y=[s * 100 for s in similarities],
                                        marker_color='#1f77b4',
                                        text=[f'{s*100:.1f}%' for s in similarities],
                                        textposition='auto'
                                    )
                                ])

                                fig.update_layout(
                                    title="–°—Ö–æ–∂–µ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π",
                                    xaxis_title="–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ",
                                    yaxis_title="–°—Ö–æ–∂–µ—Å—Ç—å (%)",
                                    height=400,
                                    xaxis_tickangle=-45
                                )

                                st.plotly_chart(fig, width='stretch')
                                
                                # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                                st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                                csv_data = df.to_csv(index=False, encoding='utf-8')
                                st.download_button(
                                    label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
                                    data=csv_data,
                                    file_name=f"recommendations_{selected_db}_{target.get('name', 'compound')}.csv",
                                    mime="text/csv",
                                    use_container_width=True
                                )

                    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
                    st.divider()
                    st.subheader("üìà –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")

                    col1, col2 = st.columns(2)
                    with col1:
                        n_clusters = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:", 2, 10, 5)
                    with col2:
                        algorithm_options = {
                            "kmeans": "K-means (—Å—Ñ–µ—Ä–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã)",
                            "dbscan": "DBSCAN (–ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞)",
                            "agglomerative": "–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è (–¥—Ä–µ–≤–æ–≤–∏–¥–Ω–∞—è)"
                        }
                        selected_algorithm = st.selectbox(
                            "–ê–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:",
                            options=list(algorithm_options.keys()),
                            format_func=lambda x: algorithm_options[x]
                        )

                    if st.button("üéØ –í—ã–ø–æ–ª–Ω–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é", width='stretch'):
                        with st.spinner("–í—ã–ø–æ–ª–Ω—è—é –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é..."):
                            cluster_results = engine.cluster_compounds(
                                compounds_list, selected_db, n_clusters, selected_algorithm
                            )

                            if "error" not in cluster_results:
                                st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {cluster_results['n_clusters']} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∏–∑ {cluster_results['total_compounds']} —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")
                                st.info(f"üéØ –ê–ª–≥–æ—Ä–∏—Ç–º: {algorithm_options[selected_algorithm]}")

                                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
                                if "quality_metrics" in cluster_results and "warning" not in cluster_results["quality_metrics"]:
                                    metrics = cluster_results["quality_metrics"]
                                    st.subheader("üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")

                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        if 'silhouette' in metrics:
                                            st.metric(
                                                "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∏–ª—É—ç—Ç–∞",
                                                f"{metrics['silhouette']:.3f}",
                                                help="–ß–µ–º –±–ª–∏–∂–µ –∫ 1, —Ç–µ–º –ª—É—á—à–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"
                                            )
                                    with col2:
                                        if 'calinski_harabasz' in metrics:
                                            st.metric(
                                                "–ò–Ω–¥–µ–∫—Å Calinski-Harabasz",
                                                f"{metrics['calinski_harabasz']:.1f}",
                                                help="–ß–µ–º –≤—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –ª—É—á—à–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"
                                            )
                                    with col3:
                                        if 'davies_bouldin' in metrics:
                                            st.metric(
                                                "–ò–Ω–¥–µ–∫—Å Davies-Bouldin",
                                                f"{metrics['davies_bouldin']:.3f}",
                                                help="–ß–µ–º –Ω–∏–∂–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Ç–µ–º –ª—É—á—à–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"
                                            )
                                elif "quality_metrics" in cluster_results and "warning" in cluster_results["quality_metrics"]:
                                    st.warning(cluster_results["quality_metrics"]["warning"])

                                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                                clusters = cluster_results['clusters']
                                
                                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                                st.subheader("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")

                                cluster_sizes = [len(cluster_compounds) for cluster_compounds in clusters.values()]
                                cluster_labels = [f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}" for cluster_id in clusters.keys()]

                                # –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
                                fig_pie = go.Figure(data=[
                                    go.Pie(
                                        labels=cluster_labels,
                                        values=cluster_sizes,
                                        textinfo='label+percent',
                                        insidetextorientation='radial'
                                    )
                                ])

                                fig_pie.update_layout(
                                    title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º",
                                    height=400
                                )

                                col1, col2 = st.columns([2, 1])
                                with col1:
                                    st.plotly_chart(fig_pie, width='stretch')

                                with col2:
                                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                                    st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                                    st.metric("–í—Å–µ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", len(clusters))
                                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä", max(cluster_sizes))
                                    st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä", min(cluster_sizes))
                                    avg_size = sum(cluster_sizes) / len(cluster_sizes)
                                    st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä", ".1f")

                                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
                                export_data = []
                                for cluster_id, cluster_compounds in clusters.items():
                                    for comp in cluster_compounds:
                                        export_data.append({
                                            "–ö–ª–∞—Å—Ç–µ—Ä": f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1}",
                                            "–ù–∞–∑–≤–∞–Ω–∏–µ": comp.get('name', '‚Äî'),
                                            "–§–æ—Ä–º—É–ª–∞": comp.get('formula', '‚Äî'),
                                            "–ú–∞—Å—Å–∞": comp.get('exact_mass', '‚Äî'),
                                            "–¢–∏–ø": database_options[selected_db]
                                        })

                                # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                                if export_data:
                                    st.subheader("üíæ –≠–∫—Å–ø–æ—Ä—Ç –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
                                    export_df = pd.DataFrame(export_data)
                                    csv_cluster_data = export_df.to_csv(index=False, encoding='utf-8')
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã (CSV)",
                                        data=csv_cluster_data,
                                        file_name=f"clusters_{selected_db}_{n_clusters}_clusters.csv",
                                        mime="text/csv",
                                        use_container_width=True
                                    )

                                for cluster_id, cluster_compounds in clusters.items():
                                    with st.expander(f"–ö–ª–∞—Å—Ç–µ—Ä {cluster_id + 1} ({len(cluster_compounds)} —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π)"):
                                        cluster_data = []
                                        for comp in cluster_compounds[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                                            cluster_data.append({
                                                "–ù–∞–∑–≤–∞–Ω–∏–µ": comp.get('name', '‚Äî'),
                                                "–§–æ—Ä–º—É–ª–∞": comp.get('formula', '‚Äî'),
                                                "–ú–∞—Å—Å–∞": f"{comp.get('exact_mass', 0):.2f}" if comp.get('exact_mass') else "‚Äî"
                                            })

                                        if cluster_data:
                                            cluster_df = pd.DataFrame(cluster_data)
                                            st.dataframe(cluster_df, width='stretch', hide_index=True)
                                            
                                            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
                                            st.subheader("üîß –î–µ–π—Å—Ç–≤–∏—è —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞")
                                            
                                            for i, comp in enumerate(cluster_compounds[:10]):
                                                with st.container():
                                                    col1, col2 = st.columns([3, 1])
                                                    
                                                    with col1:
                                                        st.markdown(f"**{comp.get('name', '‚Äî')}**")
                                                    
                                                    with col2:
                                                        # –ö–Ω–æ–ø–∫–∞ –ø–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏
                                                        if st.button(f"üìã –î–µ—Ç–∞–ª–∏", key=f"cluster_details_{cluster_id}_{i}_{comp.get('id', i)}", use_container_width=True):
                                                            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥ –¥–µ—Ç–∞–ª–µ–π
                                                            try:
                                                                from ..main import open_dialog_safely
                                                            except ImportError:
                                                                try:
                                                                    from main import open_dialog_safely
                                                                except ImportError:
                                                                    # Fallback —Ñ—É–Ω–∫—Ü–∏—è
                                                                    def open_dialog_safely(dialog_type: str, entity: Dict[str, Any]):
                                                                        st.session_state[f"show_{dialog_type}_details"] = True
                                                                        st.session_state[f"selected_{dialog_type}"] = entity
                                                                    
                                                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                                                            if selected_db == "metabolites":
                                                                open_dialog_safely("metabolite", comp)
                                                            elif selected_db == "enzymes":
                                                                open_dialog_safely("enzyme", comp)
                                                            elif selected_db == "proteins":
                                                                open_dialog_safely("protein", comp)
                                                            elif selected_db == "carbohydrates":
                                                                open_dialog_safely("carbohydrate", comp)
                                                            elif selected_db == "lipids":
                                                                open_dialog_safely("lipid", comp)
                                                            
                                                        # –ö–Ω–æ–ø–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é
                                                        if st.button(f"‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç—å", key=f"cluster_compare_{cluster_id}_{i}_{comp.get('id', i)}", use_container_width=True):
                                                            try:
                                                                from .comparison import add_to_comparison_button, comparison_comparator
                                                                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é
                                                                add_to_comparison_button(comp, selected_db, comparison_comparator)
                                                                st.success(f"‚úÖ {comp.get('name', '–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ')} –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é")
                                                            except Exception as e:
                                                                st.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é: {e}")
                                                    
                                                    st.divider()

                            else:
                                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {cluster_results['error']}")

            else:
                st.warning("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    with st.expander("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"):
        st.markdown("""
        **üéØ –°–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π** –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ:

        - **–¢–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞**: –æ–±—â–∏–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
        - **–•–∏–º–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–∞–≤–∞**: –æ–±—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º—É–ª–∞—Ö
        - **–ú–æ–ª–µ–∫—É–ª—è—Ä–Ω–æ–π –º–∞—Å—Å—ã**: –±–ª–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–∞—Å—Å
        - **–°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞**: –º–æ–ª–µ–∫—É–ª—è—Ä–Ω—ã–µ fingerprints (—Ç—Ä–µ–±—É–µ—Ç RDKit)
        - **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤**: –¥–ª—è —Ñ–µ—Ä–º–µ–Ω—Ç–æ–≤ –∏ –±–µ–ª–∫–æ–≤

        **–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è** –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ —Å—Ö–æ–∂–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º.

        **–ê–ª–≥–æ—Ä–∏—Ç–º—ã**: TfidfVectorizer, K-means, Tanimoto similarity, Morgan fingerprints.
        """)
